---
title: "[2025.09.20更新] UbuntuにNVIDIA DriverとCUDA, Dockerをインストールして機械学習サーバを構築する"
emoji: "😉"
type: "tech"
topics:
  - "docker"
  - "ubuntu"
  - "nvidia"
  - "server"
  - "cuda"
published: true
published_at: "2024-03-06 22:28"
---

こんにちは．今回はNVIDIA Driver, CUDA, Container Toolkitをインストールして，DockerコンテナやPyTorch，TensorflowなどをNVIDIA GPUを利用して実行するための環境を構築する手順を書きます．

巷ではこういう記事がたくさん出ているかと思いますが，本記事では，研究室や社内などで共有利用するサーバの構築を想定している点が他の記事との相違点です．

私は今まではNVIDIA社の佐々木氏が書いていた，以下の[「NVIDIA Docker って今どうなってるの？ (20.09 版)」](https://medium.com/nvidiajapan/nvidia-docker-って今どうなってるの-20-09-版-558fae883f44)にお世話になっていたのですが，近年状況も変わってきているので，ここで一旦まとめます．

https://medium.com/nvidiajapan/nvidia-docker-って今どうなってるの-20-09-版-558fae883f44

本記事では以下のような環境を構築することを目的とします．

- Ubuntu 24.04 or 22.04 LTS Server(Desktopも可)
- Docker
- NVIDIA Driver, CUDA, NVIDIA Docker

## 更新履歴

> - 2025.09.20 nvidia-openドライバの記述追加．画像の差し替え．表現の修正．
> - 2025.06.07 languagepack-jaを追加，uvの記述を追加
> - 2024.12.31 Ubuntu24.04の記述を追加

## Ubuntuのインストール・設定

まずはサーバーにUbutntu 24.04 LTS Server or Desktopをインストールします．

~~この記事を書いている時点ではあと1ヶ月で24.04 LTSが出るところですが，各種ライブラリが対応するまでは22.04で良いでしょう．~~

(2024.12.31更新) Ubuntu 24.04でもインストールが安定してきたので、Ubuntuのバージョンを更新しました。22.04とほとんど同様です。

Ubuntuのインストールは各自好きな方法で行ってください．
私は以下のような設定でいつも入れています．

- server minimizeを選択
- サードパーティライブラリはインストールしない
- partition: use as bootを選択してboot領域を1GB割り当てて，残りを`/`(ルート)にマウント
- OpenSSH-ServerをInstall
- (デスクトップ) NetworkManagerからnetplanへ切り替え

ネットワークの設定はNICを複数束ねてbondingする場合であっても，インストール後にnetplanをいじった方が楽です．
Ubuntuをインストールし終わったら，コンソールにログインしてリモートで作業ができるように設定を行なっていきます．

### パッケージインストール

まずはお好きなライブラリのインストールから

```bash
sudo apt update
sudo apt upgrade

sudo apt install -y \
    avahi-daemon git vim emacs build-essential \
    wget curl jq ffmpeg htop tmux screen parallel \
    imagemagick geeqie iputils-ping net-tools zsh \
    language-pack-ja

# (2025.06.07更新) uvのみ使う場合は以下は実行しなくても良いです．
# Pythonのビルドができるようにパッケージをインストール
sudo apt install -y \
    build-essential libssl-dev zlib1g-dev \
    libbz2-dev libreadline-dev libsqlite3-dev curl \
    libncursesw5-dev xz-utils tk-dev libxml2-dev libxmlsec1-dev \
    libffi-dev liblzma-dev
```

インストールしたパッケージについて簡単に説明します．

- `git, wget, curl` 必須
- `avahi-daemon` mDNSのためのライブラリで，入れておくとDNSを立てなくてもローカルLANから`ssh server.local`などでWindows, macOS, Linuxのどこからでもアクセスできます．
- `emacs, vim` 両方入れておけば戦争を回避できます．
- `build-essential` ビルドするためのライブラリが色々入ります
- `jq` json parser．機械学習データセットの情報はjsonで提供されていることもあるので入れます
- `ffmpeg` コマンドラインから動画を処理できます
- `imagemagick` コマンドラインから画像を扱えます
- `tmux, screen` ログアウト後もシェルを維持できるので，時間の長い学習スクリプトを回す時に利用します．`nohup`でもいいです．
- `parallel` サーバーマシンは大体コア数が多いので，並列処理して効率化しましょう．`xargs`でもいいです
- `htop` システムの使用状況を見れます．`top`でもいいですが，htopの方が見やすいのでこちらを入れてます．
- `geeqie` 画像ビュワーです．軽いのでXwindow越しでも使えます．
- `iputils-ping, net-tools` `ping`で他のサーバの状況やインターネットの疎通確認に使えます．
- `zsh` 好きなshellを入れてください．
- `language-pack-ja` 日本語環境を入れて表示できるようにする．

~~2つ目の`apt install`はPythonをビルドするためのパッケージです．サーバの利用者の中には`pyenv`あたりを利用する人もいると思うので，入れておきましょう．~~

(2025.06.07更新)
Pythonのパッケージマネージャはuvが主流になったので，2つ目の`apt install`はお好みで実行してください．

### ネットワーク設定

次にネットワークを設定します．
Ubuntu Serverはnetplanでネットワークの設定を行うので，`/etc/netplan`以下のyamlファイルの設定を行います．
Ubuntu Desktopの場合はNetworkManagerから行ってください．
IPアドレスを固定する場合は，以下のように設定します．

Ubuntu22.04から`gateway4`の書き方が`routes`に変わっているので注意です．

```yaml
# This is the network config written by 'subiquity'
network:
  ethernets:
    enp42s0:
      dhcp4: false
      addresses:
        - 192.168.0.2/24
      nameservers:
        addresses: [192.168.0.1]
      # 以下はダメ
      # gateway4: 192.168.0.1
      # routesで書く
      routes:
        - to: default
          via: 192.168.0.1
  version: 2
```

設定が終わったら`sudo netplan apply`で設定を有効化します．

### SSHの設定

次にSSH-Serverの設定を行います．
ここは環境によって変わるかと思いますので，各自設定してください．
ローカルLANに置く場合は，`PermitRootLogin`や`PasswordAuthentication no`あたりをしておけばいいです．

ここまで終わればリモートから作業できますので，サーバーをラックに入れるなりしておいてください．
NFSやLDAPを設定する場合はここでやるか，ラックに入れてから行いましょう．

## Dockerのインストール

次にDockerのインストールを行います．
最近はLinuxでもDocker Desktopが出ていますが，Linuxは基本Engineで大丈夫でしょう．

以下の公式サイトの下の方に「Install using the convenience script」という項目があり，用意されたインストールスクリプトをダウンロードして簡単に導入できます．

https://docs.docker.com/engine/install/ubuntu/#install-using-the-convenience-script

```bash
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
```

Dockerのインストールが終わったら，ユーザーがsudoなしでdockerを扱えるようにユーザーをdockerグループに入れておきます．

```bash
sudo gpasswd -a [ユーザー名] docker
```

共用サーバの場合，rootless Dockerを使うのもありです．その場合はNVIDIA Dockerを導入するためのコマンドが若干異なるので注意してください．

## NVIDIA Driver, CUDA Toolkit, Container Toolkitのインストール

次に機械学習の肝となる，NVIDIA GPUを扱うためのドライバーやCUDAを入れていきます．

### aptリポジトリの登録

まずは，aptでツールをインストールできるように，
以下のダウンロードサイトから環境を選択して，cuda-keyringをインストールします．

https://developer.nvidia.com/cuda-downloads

![cuda download page](/images/nvidia-cuda-download.png)

今回のUbuntu 24.04の場合は

- Linux
- x86_64 (armの場合はarm64-sbsa)
- Ubuntu
- 24.04
- deb(network)

を選択します．選択すると以下の画像のように，インストールするためのコマンドが表示されます．

![cuda download page got cli](/images/nvidia-cuda-download-cli.png)

表示されたインストールコマンドのうち，下記のように`sudo apt-get update`まで行います．

```bash
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb
sudo apt-get update
```

以上で，apt installを使って各種ツールをインストールする準備が整いました．

### NVIDIA Driverのインストール

次にNVIDIA Driverのインストールを行います．

先ほどのダウンロードサイトで，OS等を選択すると，以下の画像のようなコマンドが出ているかと思います．

![nvidia-driver-install-cli](/images/nvidia-driver-install-cli.png)

NVIDIA Driverをインストールする方法として，プロプライエタリな`cuda-driver`を入れる方法と，オープンな`nvidia-open`を入れる選択肢があります．
ここではオープン版の`nvidia-open`をインストールすることを推奨します．
これは，オープン版のドライバの方が最新のGPUに早く対応するためです．
例えば，現在最新のRTX PRO 6000 Blackwellが出た当初は，`nvidia-open`のドライバしか対応していませんでした．
今後，新しいGPUが出た場合は，オープン版が先に対応する方針なのかもしれません．

以下のコマンドでオープン版のドライバをインストールできます．

```bash
sudo apt install -y nvidia-open
```

すでに既存のプロプライエタリのドライバ(`cuda-drivers`)がインストールされていて，オープン版に移行する場合は，以下のコマンドを実行します．

```bash
apt install --autoremove --purge nvidia-open
```

### CUDA Toolkitのインストール

次に，CUDA Toolkitのインストールを行います．
もし，実行環境を完全にDockerコンテナの中に閉じ込める場合は，CUDAのインストールは必要ないため，この節を飛ばしてください．

CUDAをインストールできるaptパッケージには，以下の種類があります．

https://docs.nvidia.com/cuda/cuda-installation-guide-linux/#meta-packages

![nvidia-cuda-packages](/images/nvidia-cuda-packages.png)

上記の表を見ると，`sudo apt install cuda`を行えばDriverもCUDAも入って良さそうですが，DriverとCUDAのいずれかのみをupgradeしたい場合に，依存関係で両方upgradeしなければならなくなります．  
よって，ここでは`cuda-toolkit`をインストールすることで，依存関係をわけてCUDAをインストールします．

```bash
sudo apt install -y cuda-toolkit
```

CUDAのバージョンですが，ユーザーには基本的にDockerを用いてもらうことで，ホストマシンはとりあえず最新を入れておけば良くなります．なんなら、CUDA自体のインストールも必要ないです。Dockerを布教しておきましょう．

### cuDNNのインストール

cuDNNはNVIDIA CUDA Deep Neural Network libraryの略で，有効にするとDNNの処理の一部でGPU向けに高速化された実装を利用できます．
以下のコマンドでインストールできます．

```bash
sudo apt install cudnn
```

### NVIDIA Docker

NVIDIA Dockerは現在はNVIDIA Container Toolkitと呼ばれる体系の中にあります．
なので，DockerコンテナからNVIDIA GPUを扱うにはnvidia-container-toolkitを入れます．

https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/index.html

```bash
sudo apt-get install -y nvidia-container-toolkit
```

次にDockerの設定を行います．
rootless Dockerの場合は，ここでコマンドが異なりますので注意してください．([Docker公式ドキュメント](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#rootless-mode)を参照)

```bash
sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker
```

次にDockerのconfigをいじります．以下の公式ドキュメン度，Qiitaの記事やGithubのIssueで言われているように，「起動中のDockerコンテナでGPUが使えてたのにしばらくすると使えなくなる」現象があります．これはdockerのcgroupの管理がsystemdになっているために`systemctl daemon-reload`した時にGPUの認識がおかしくなるようです．

https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/troubleshooting.html#containers-losing-access-to-gpus-with-error-failed-to-initialize-nvml-unknown-error

https://qiita.com/tttamaki/items/4f369633b7f53f5131a1

回避策として，DockerのCgroup Driverをsystemdからcgroupfsに変更します．

Dockerをデフォルトで入れた時，`docker info`は以下のようになっています．

```bash
docker info

# 中略
 Cgroup Driver: systemd
 Cgroup Version: 2
```

編集するファイルは`/etc/docker/daemon.json`です．

```bash
{
    "runtimes": {
        "nvidia": {
            "args": [],
            "path": "nvidia-container-runtime"
        }
    },
    "exec-opts": ["native.cgroupdriver=cgroupfs"]
}
```

ここで追加するのは`"exec-opts": ["native.cgroupdriver=cgroupfs"]`の行です．
書き込みが終わったらdockerを再起動して，変更ができているか確認します．

```bash
sudo systemctl restart docker
docker info

# 中略
 Cgroup Driver: cgroupfs
 Cgroup Version: 2
```

`cgroupfs`になっていればOKです．

## 再起動&確認

ここでNVIDIA Driverを有効にするために，サーバーの再起動を行います．

```bash
sudo reboot now
```

再起動をしたら，.bashrcにPATHを通します．

```bash
export PATH="/usr/local/cuda/bin:$PATH"
export LD_LIBRARY_PATH="/usr/local/cuda/lib64:$LD_LIBRARY_PATH"
export CUDA_HOME="/usr/local/cuda"
```

```bash
source ~/.bashrc
```

そしてホストマシンと，コンテナ内の両方でGPUを認識できるかを確認します．

- ホストマシン

```bash
nvidia-smi

+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX PRO 6000 Blac...    On  |   00000000:10:00.0 Off |                  Off |
| 71%   87C    P1            299W /  300W |   42650MiB /  97887MiB |    100%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A         3816827      C   /opt/venv/bin/python                  42640MiB |
+-----------------------------------------------------------------------------------------+

nvidia-smi -L

GPU 0: NVIDIA RTX PRO 6000 Blackwell Max-Q Workstation Edition (UUID: GPU-...)
```

- コンテナ

```bash
docker run --rm --gpus all ubuntu:latest nvidia-smi

+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX PRO 6000 Blac...    On  |   00000000:10:00.0 Off |                  Off |
| 72%   87C    P1            299W /  300W |   42650MiB /  97887MiB |    100%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
```

上記のように認識されていればOKです．

次にCUDAのバージョンを確認します．以下のように表示されていればOKです．

```bash
nvcc -V

nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2025 NVIDIA Corporation
Built on Wed_Jul_16_07:30:01_PM_PDT_2025
Cuda compilation tools, release 13.0, V13.0.48
Build cuda_13.0.r13.0/compiler.36260728_0
```

## NVIDIA DriverとCUDAの自動アップグレードの停止

Ubuntuのパッケージマネージャのaptはパッケージの自動更新の仕組みがあるのですが，NVIDIA Driverが自動更新されると，Loadされているドライバと実際のバージョンのミスマッチを起こして`nvidia-smi`実行時に`Failed to initialize NVML: Driver/library version mismatch`エラーがでます。ステータスが見られず，新しいジョブが投げられなくなったりします．
なので，長期運用するためにはNVIDIA系のライブラリは自動更新を止めることをお勧めします．

自動更新を止めるには，`/etc/apt/apt.conf.d/50unattended-upgrades`を編集します．
上の方にある`Unattended-Upgrade::Package-Blacklist`に`.*nvidia, .*libnvidia, .*cuda`を追加します．

```python
// Python regular expressions, matching packages to exclude from upgrading
Unattended-Upgrade::Package-Blacklist {
    // The following matches all packages starting with linux-
//  "linux-";

    // Use $ to explicitely define the end of a package name. Without
    // the $, "libc6" would match all of them.
//  "libc6$";
//  "libc6-dev$";
//  "libc6-i686$";

    // Special characters need escaping
//  "libstdc\+\+6$";

    // The following matches packages like xen-system-amd64, xen-utils-4.1,
    // xenstore-utils and libxenstore3.0
//  "(lib)?xen(store)?";

    // For more information about Python regular expressions, see
    // https://docs.python.org/3/howto/regex.html
    ".*nvidia";
    ".*libnvidia";
    ".*cuda";
};
```

これで自動更新が停止されます．アップグレードする際は手動で`sudo apt upgrade cuda-driver cuda-toolkit`を実行してください．

ちなみに，データセンタ用のGPU(Tesla, RTX A6000, RTX 6000Ada, A100, H100など)はDriverのバージョンが古くても，新しいバージョンのCUDAを実行できる
Forward capabilityという機能があります．そのためDGX-A100などは自動更新されないようになっているので，基本的に自動更新は止めて良いと思います．

以上で機械学習サーバの構築は完了です．お疲れ様でした！
